#import "../lib.typ":*
#import "@preview/callisto:0.2.4"
#show: doc.with(hw-id: 5)


#let (render, result) = callisto.config(nb: json("hw5.ipynb"))


= 实验要求
+ 请结合这些学科排名数据，分析全球高校可以大致分为哪几类?并且分析出与华师大类似的高校?

+ 请通过探索性分析的方式，对华东师范大学做一个学科画像?用尽可能多的角度去做。
+ 请利用数据建模的方式，对各学科做一个排名模型，能够较好的预测出排名位置。(可以用各学科前60%的数据作为训练集，后20%的数据作为测试集)

= 具体实现
== 准备工作

=== 定义基本的参数、可复用函数
首先，我们需要导入必要的库，并加载数据集。

我们使用 `pandas` 来处理数据，`numpy` 来进行数值计算，`matplotlib` 和 `seaborn` 来进行数据可视化，使用 `scikit-learn` 来进行机器学习建模。
#render(0)

接下来，我们定义一下全局的配置，包括数据库文件所在的路径、院校的名称等。
#render(1)

然后，是一些数据预处理的工作，包括从数据库加载数据、预处理数据为：按照每个机构的名字进行聚合数据。

#render(2)

=== 数据准备
接下来，我们导入数据库中的数据，并进行简单的展示。
#render(3)

== 数据分析与建模

=== 分析

这个任务包含两个子任务：

- *全球高校分类*：我们想知道全球高校可以“大致分为哪几类”。当数据中没有现成的“类别”标签，而我们想根据数据的相似性自动找出“群体”时，这是一个聚类问题。

- *寻找相似高校*：我们想找到与“华师大”特征相似的其他高校。这是一个相似性匹配或距离计算问题。

=== 思路与模型

我的思路是首先将数据从“学校-学科”粒度聚合到“学校”粒度，为每所高校构建一个“画像”，然后基于这个画像同时解决上述两个问题。

- *数据聚合：*

  - 原始数据是 `[机构, 学科, 排名, ...]`。
  - 我需要将其转换为 `[机构, 总入围学科数, 平均排名, 总论文数, 总引用数, 总高被引论文数, 平均篇均引用]`。

- *模型选型* (聚类)：
  - 算法：我选用 K-Means 聚类算法。

  - 原因：K-Means 是一种高效且直观的聚类算法，适合处理当前这种“特征画像”数据。

  - 前置处理：K-Means 是基于距离的，而“总引用数”（数百万）和“总学科数”（数十）的尺度完全不同。因此，在聚类前，我必须使用 StandardScaler 对所有特征进行标准化，使其均值为0，方差为1，消除尺度影响。

- *模型选型* (相似性)：

  - 算法：我选用基于欧氏距离的相似度计算。

  - 原因：在聚类时，我们已经对数据进行了标准化。在同一个标准化空间中，欧氏距离是衡量两个点（两所学校）“绝对相似度”的最直观方法。距离越近，代表两所学校的画像越相似。

  - 步骤：
    1. 提取“华师大”的标准化特征向量。 

    2. 计算它与所有其他学校向量的欧氏距离。 
    3. 排序，找出距离最小的（即最相似的）。

#render(4)

== 学科画像 
=== 分析

这个任务要求对华师大做“学科画像”，并“用尽可能多的角度”。

=== 思路与模型 

我的思路是，从原始的“学校-学科”数据中，筛选出所有“华师大”的记录，然后从多个维度进行描述和可视化。

- *数据筛选*：从原始 `df` 中过滤 `institution == 'EAST CHINA NORMAL UNIVERSITY'`。

- *分析角度：*

  - 学科广度：总共有多少个学科入围？(对 `research_field` 计数)。

  - 学科高度：哪些学科排名最靠前？(按 `rank` 升序排序)。

  - 学科影响力：哪些学科的高被引论文 (`top_papers`) 最多？(按 `top_papers` 降序排序)。

  - 学科学术质量：哪些学科的篇均引用 (`cites_per_paper`) 最高？(按 `cites_per_paper` 降序排序)。

- *可视化：*

  - 算法/工具：使用 `matplotlib` 和 `seaborn` 库。

  - 图表：对上述角度 2, 3, 4，分别使用条形图进行可视化。条形图最适合展示不同类别（学科）在某个数值指标（排名、高被引、篇均引）上的对比。

#render(5)

== 学科排名预测模型

=== 分析
这是一个典型的监督学习问题。由于 `rank` 是一个连续的数值（或至少是高基数的有序数值），这具体来说是一个回归问题。

=== 思路与模型

- *特征 ($X$) 和 目标 ($y$)*
  - 目标 ($y$)：`rank`

  - 特征 ($X$)：`documents`, `cites`, `cites_per_paper`, `top_papers` (数值特征)，以及 `research_field` (类别特征)。
  - `research_field` 很重要因为 ESI 排名是“在特定学科内”排名的。不同学科的竞争激烈程度和数据分布（如临床医学有几千个机构上榜，而空间科学可能只有几百个）截然不同。因此，模型必须知道它正在为哪个学科进行预测。

- *数据拆分*
  - 各学科前60%的数据作为训练集，后20%的数据作为测试集

  - 我的思路是
    - 遍历每一个 `research_field`。

    - 在同学科内，按 `rank` 升序排序。
    - 使用 `iloc` 按比例切片。
    - 将所有学科的切片重新组合成最终的 `X_train`, `y_train`, `X_test`, `y_test`
- *预处理* 
  - 我们需要一个 Pipeline 来处理混合数据。

  - 数值特征 (`documents`, `cites` 等) 可以直接使用
  - 类别特征必须进行独热编码，将其转换为模型可以理解的 0/1 矩阵。
  - `ColumnTransformer` 是实现这一点的最佳工具。
- *模型选型*
  - 算法选用随机森林回归。

  - 原因：
    - 鲁棒性 ：对数据尺度不敏感，不需要复杂的特征缩放。

    - 非线性：它能很好地捕捉 `cites` 和 `rank` 之间的非线性关系（例如，引用数加倍，排名可能提升远不止两倍）。交互性：能自动捕捉特征间的交互作用（例如 `cites` 对 `rank` 的影响，在 "化学" 和 "数学" 领域是不同的）。
    - 可解释性：可以提供“特征重要性”，让我们知道哪个指标对 ESI 排名的预测贡献最大。
- *评估*
  - $R^2$：模型解释了多少百分比的方差？(越接近1越好)。

  - RMSE：模型的预测平均偏离了多少个“名次”？(越低越好)。

#render(6)

#remark[
  完整代码见 `./hw5.ipynb`。
]